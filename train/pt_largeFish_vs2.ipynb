{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pt_largeFish_vs2.ipynb","provenance":[],"machine_shape":"hm","collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"b657d460a5e846e4aad85859a4c3a890":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c11da44e282f4a8b96dd6a0f738bd2f9","IPY_MODEL_7b118c232b8e406b9373fd5624192fda","IPY_MODEL_b48e0b305c4440508d9617172c57b51b"],"layout":"IPY_MODEL_071ae621e7db450c98e70e2284b3263b"}},"c11da44e282f4a8b96dd6a0f738bd2f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6840c3c96dd4b619c7228c4bd4147ff","placeholder":"​","style":"IPY_MODEL_e46b6f04642d49ca99cc0a604d84f2e4","value":"Validation sanity check: 100%"}},"7b118c232b8e406b9373fd5624192fda":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_9cec10754c9444b28d20fa40a994024f","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c2b1a39b3a28419bba2d58f8186d3ad8","value":1}},"b48e0b305c4440508d9617172c57b51b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c3eb955b5a340c0a0eeb79b2f9d3827","placeholder":"​","style":"IPY_MODEL_9bcd99a4a54f491eb51ec3c8f26fd8c7","value":" 1/1 [00:01&lt;00:00,  1.86s/it]"}},"071ae621e7db450c98e70e2284b3263b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"e6840c3c96dd4b619c7228c4bd4147ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e46b6f04642d49ca99cc0a604d84f2e4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9cec10754c9444b28d20fa40a994024f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2b1a39b3a28419bba2d58f8186d3ad8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9c3eb955b5a340c0a0eeb79b2f9d3827":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9bcd99a4a54f491eb51ec3c8f26fd8c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f14eb3fbb4f4d608a5c7b96338ac07c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_194d1528c926410f8e34a593b89f8fcc","IPY_MODEL_c7d1c23f0fe74ce596b4970f56810042","IPY_MODEL_f81ef4896e6848509adaf8083df733f8"],"layout":"IPY_MODEL_39f34bb33f2144ab85701c8f75bf7052"}},"194d1528c926410f8e34a593b89f8fcc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_24aff7b4028c4f7b8979c0d44040518d","placeholder":"​","style":"IPY_MODEL_062800414ebc46c6a1f36c751aa43f13","value":"Epoch 0:   0%"}},"c7d1c23f0fe74ce596b4970f56810042":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc6aea14ddbf4c078897648680a60437","max":507,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bc7277b01c554125910402e524cef66b","value":0}},"f81ef4896e6848509adaf8083df733f8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c26d4b51bb54b9387a0b0c3e42de17d","placeholder":"​","style":"IPY_MODEL_b2e2f243ed7a4cc1a06a5f0e365464ff","value":" 0/507 [00:00&lt;?, ?it/s]"}},"39f34bb33f2144ab85701c8f75bf7052":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"24aff7b4028c4f7b8979c0d44040518d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"062800414ebc46c6a1f36c751aa43f13":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dc6aea14ddbf4c078897648680a60437":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc7277b01c554125910402e524cef66b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0c26d4b51bb54b9387a0b0c3e42de17d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2e2f243ed7a4cc1a06a5f0e365464ff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iuz1maQQhB19","executionInfo":{"status":"ok","timestamp":1647195731206,"user_tz":-420,"elapsed":6,"user":{"displayName":"Minh Nhat Trinh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUlruUlJibAIqBqbqLK2Tos6lKVv00A2KZfuwF=s64","userId":"12425805762404293245"}},"outputId":"fa59ad46-c9ef-4528-8812-9e7d94f60c6f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Mar 13 18:22:10 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   39C    P0    57W / 149W |   2012MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%run /content/drive/MyDrive/deepfish/preprocessing_2D.ipynb"],"metadata":{"id":"CUQzH7YATJwY"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"w_j5Ee9S6e5V","executionInfo":{"status":"ok","timestamp":1647195176672,"user_tz":-420,"elapsed":21965,"user":{"displayName":"Minh Nhat Trinh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUlruUlJibAIqBqbqLK2Tos6lKVv00A2KZfuwF=s64","userId":"12425805762404293245"}},"outputId":"982a70d8-344b-41ae-a451-56dcc30b6e39"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch.autograd.profiler.emit_nvtx at 0x7f7d6a3e3990>"]},"metadata":{},"execution_count":2}],"source":["!pip install pytorch-lightning\n","from torchsummary import summary\n","import pytorch_lightning as pl\n","from IPython.display import clear_output\n","import nibabel as nib\n","import csv\n","import os\n","import glob \n","import torch\n","import torch.nn as nn\n","import numpy as np\n","from tqdm import tqdm\n","import torch.nn.functional as F\n","from fastprogress import master_bar, progress_bar\n","from torchvision import transforms\n","import torch.optim as optim\n","from itertools import product\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import DataLoader, Dataset\n","import matplotlib.pyplot as plt\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","class HistoryLogger(pl.callbacks.Callback):\n","    def __init__(self, dir = \"history.csv\"):\n","        self.dir = dir\n","    def on_validation_epoch_end(self, trainer, pl_module):\n","        metrics = trainer.callback_metrics\n","        if \"loss_epoch\" in metrics.keys():\n","            logs = {\"epoch\": trainer.current_epoch}\n","            keys = [\"loss_epoch\", \"train_dice_epoch\", \"train_jac_epoch\",\n","                    \"val_loss\",\"val_dice\", \"val_jac\"\n","                    ]\n","            for key in keys:\n","                logs[key] = metrics[key].item()\n","            header = list(logs.keys())\n","            isFile = os.path.isfile(self.dir)\n","            with open(self.dir, 'a', newline='') as csvfile:\n","                writer = csv.DictWriter(csvfile, fieldnames=header)\n","                if not isFile:\n","                    writer.writeheader()\n","                writer.writerow(logs) \n","        else:\n","            pass\n","def setDropProb(model, prob=0.01):\n","    for layer in model.modules():\n","        if isinstance(layer, DropBlock2D):\n","            layer.drop_prob = prob\n","clear_output()\n","############## turn off Debug APIs for Final Training############\n","torch.autograd.set_detect_anomaly(False)\n","torch.autograd.profiler.profile(False)\n","torch.autograd.profiler.emit_nvtx(False)"]},{"cell_type":"markdown","source":["##model"],"metadata":{"id":"SfvuKiThH5eU"}},{"cell_type":"code","source":["# https://github.com/miguelvr/dropblock/blob/master/dropblock/dropblock.py\n","class DropBlock2D(nn.Module):\n","    def __init__(self, drop_prob, block_size):\n","        super(DropBlock2D, self).__init__()\n","        self.drop_prob = drop_prob\n","        self.block_size = block_size\n","    def forward(self, x):\n","        # shape: (bsize, channels, height, width)\n","        assert x.dim() == 4, \\\n","            \"Expected input with 4 dimensions (bsize, channels, height, width)\"\n","        if not self.training or self.drop_prob == 0.:\n","            return x\n","        else:\n","            # get gamma value\n","            gamma = self.drop_prob / (self.block_size ** 2)\n","            # sample mask\n","            mask = (torch.rand(x.shape[0], *x.shape[2:], device= x.device) < gamma).float()\n","            # compute block mask\n","            block_mask = self._compute_block_mask(mask)\n","            # apply block mask\n","            out = x * block_mask[:, None, :, :]\n","            # scale output\n","            out = out * block_mask.numel() / block_mask.sum()\n","            return out\n","    def _compute_block_mask(self, mask):\n","        block_mask = F.max_pool2d(input=mask[:, None, :, :],\n","                                  kernel_size=(self.block_size, self.block_size),\n","                                  stride=(1, 1),\n","                                  padding=self.block_size // 2)\n","\n","        if self.block_size % 2 == 0:\n","            block_mask = block_mask[:, :, :-1, :-1]\n","        block_mask = 1 - block_mask.squeeze(1)\n","        return block_mask\n","\n","class DropBlock3D(DropBlock2D):\n","    def __init__(self, drop_prob, block_size):\n","        super(DropBlock3D, self).__init__(drop_prob, block_size)\n","    def forward(self, x):\n","        # shape: (bsize, channels, depth, height, width)\n","        assert x.dim() == 5, \\\n","            \"Expected input with 5 dimensions (bsize, channels, depth, height, width)\"\n","        if not self.training or self.drop_prob == 0.:\n","            return x\n","        else:\n","            # get gamma value\n","            gamma = self.drop_prob / (self.block_size ** 3)\n","            # sample mask\n","            mask = (torch.rand(x.shape[0], *x.shape[2:]) < gamma).float()\n","            # place mask on input device\n","            mask = mask.to(x.device)\n","            # compute block mask\n","            block_mask = self._compute_block_mask(mask)\n","            # apply block mask\n","            out = x * block_mask[:, None, :, :, :]\n","            # scale output\n","            out = out * block_mask.numel() / block_mask.sum()\n","            return out\n","    def _compute_block_mask(self, mask):\n","        block_mask = F.max_pool3d(input=mask[:, None, :, :, :],\n","                                  kernel_size=(self.block_size, self.block_size, self.block_size),\n","                                  stride=(1, 1, 1),\n","                                  padding=self.block_size // 2)\n","        if self.block_size % 2 == 0:\n","            block_mask = block_mask[:, :, :-1, :-1, :-1]\n","        block_mask = 1 - block_mask.squeeze(1)\n","        return block_mask\n","class conv_block(nn.Sequential):\n","    def __init__(self, ch_in, ch_out, kernel_size = 3, \n","                 padding = 1, drop_block=False, block_size = 1, drop_prob = 0):\n","        super().__init__()\n","        self.add_module(\"conv1\",nn.Conv2d(ch_in, ch_out, kernel_size, padding = padding,bias=False))\n","        self.add_module(\"bn1\", nn.BatchNorm2d(ch_out))\n","        self.add_module(\"relu1\", nn.ReLU(inplace=True))\n","        self.add_module(\"conv2\",nn.Conv2d(ch_out, ch_out, kernel_size, padding = padding,bias=False))\n","        if drop_block:\n","            self.add_module(\"drop_block\", DropBlock2D(block_size = block_size, drop_prob = drop_prob))\n","        self.add_module(\"bn2\", nn.BatchNorm2d(ch_out))\n","        self.add_module(\"relu2\", nn.ReLU(inplace=True))\n","\n","class up_conv(nn.Module):\n","    def __init__(self,ch_in,ch_out):\n","        super(up_conv,self).__init__()\n","        self.up = nn.Sequential(\n","            nn.Upsample(scale_factor=2),\n","            nn.Conv2d(ch_in,ch_out,kernel_size=2,stride=1,padding=\"same\",bias=False,),\n","\t\t    nn.BatchNorm2d(ch_out),\n","\t\t\tnn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self,x):\n","        x = self.up(x)\n","        return x\n","\n","class U_Net(nn.Module):\n","    def __init__(self,img_ch=3,output_ch=2, drop_prob = 0):\n","        super(U_Net,self).__init__()\n","        \n","        self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n","        channel = 32\n","        self.Conv1 = conv_block(ch_in=img_ch,ch_out=channel)\n","        self.Conv2 = conv_block(ch_in=channel,ch_out=channel*2)\n","        self.Conv3 = conv_block(ch_in=channel*2,ch_out=channel*4)\n","        self.Conv4 = conv_block(ch_in=channel*4,ch_out=channel*8, drop_block=True, block_size = 5, drop_prob = drop_prob)\n","        self.Conv5 = conv_block(ch_in=channel*8,ch_out=channel*16, drop_block=True, block_size = 3, drop_prob = drop_prob)\n","\n","        self.Up5 = up_conv(ch_in=channel*16,ch_out=channel*8)\n","        self.Up_conv5 = conv_block(ch_in=channel*16, ch_out=channel*8)\n","\n","        self.Up4 = up_conv(ch_in=channel*8,ch_out=channel*4)\n","        self.Up_conv4 = conv_block(ch_in=channel*8, ch_out=channel*4)\n","        \n","        self.Up3 = up_conv(ch_in=channel*4,ch_out=channel*2)\n","        self.Up_conv3 = conv_block(ch_in=channel*4, ch_out=channel*2)\n","        \n","        self.Up2 = up_conv(ch_in=channel*2,ch_out=channel)\n","        self.Up_conv2 = conv_block(ch_in=channel*2, ch_out=channel)\n","\n","        self.Conv_1x1 = nn.Sequential(\n","            nn.Conv2d(channel, output_ch,kernel_size=1,stride=1,padding=0), \n","            nn.Softmax(dim=1)\n","            )\n","\n","\n","    def forward(self,x):\n","        # encoding path\n","        x1 = self.Conv1(x)\n","\n","        x2 = self.Maxpool(x1)\n","        x2 = self.Conv2(x2)\n","        \n","        x3 = self.Maxpool(x2)\n","        x3 = self.Conv3(x3)\n","\n","        x4 = self.Maxpool(x3)\n","        x4 = self.Conv4(x4)\n","\n","        x5 = self.Maxpool(x4)\n","        x5 = self.Conv5(x5)\n","\n","        # decoding + concat path\n","        d5 = self.Up5(x5)\n","        d5 = torch.cat((x4,d5),dim=1)\n","        \n","        d5 = self.Up_conv5(d5)\n","        \n","        d4 = self.Up4(d5)\n","        d4 = torch.cat((x3,d4),dim=1)\n","        d4 = self.Up_conv4(d4)\n","\n","        d3 = self.Up3(d4)\n","        d3 = torch.cat((x2,d3),dim=1)\n","        d3 = self.Up_conv3(d3)\n","\n","        d2 = self.Up2(d3)\n","        d2 = torch.cat((x1,d2),dim=1)\n","        d2 = self.Up_conv2(d2)\n","\n","        d1 = self.Conv_1x1(d2)\n","\n","        return d1\n","\n","class Attention_block(nn.Module):\n","    def __init__(self,F_g,F_l,F_int):\n","        super(Attention_block,self).__init__()\n","        self.W_g = nn.Sequential(\n","            nn.Conv2d(F_g, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n","            nn.BatchNorm2d(F_int)\n","            )\n","        \n","        self.W_x = nn.Sequential(\n","            nn.Conv2d(F_l, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n","            nn.BatchNorm2d(F_int)\n","        )\n","\n","        self.psi = nn.Sequential(\n","            nn.Conv2d(F_int, 1, kernel_size=1,stride=1,padding=0,bias=True),\n","            nn.BatchNorm2d(1),\n","            nn.Sigmoid()\n","        )\n","        \n","        self.relu = nn.ReLU(inplace=True)\n","        \n","    def forward(self,g,x):\n","        g1 = self.W_g(g)\n","        x1 = self.W_x(x)\n","        psi = self.relu(g1+x1)\n","        psi = self.psi(psi)\n","\n","        return x*psi\n","\n","class AttU_Net(nn.Module):\n","    def __init__(self,img_ch=3,output_ch=2, drop_prob=0):\n","        super(AttU_Net,self).__init__()\n","        \n","        self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n","\n","        self.Conv1 = conv_block(ch_in=img_ch,ch_out=64)\n","        self.Conv2 = conv_block(ch_in=64,ch_out=128)\n","        self.Conv3 = conv_block(ch_in=128,ch_out=256)\n","        self.Conv4 = conv_block(ch_in=256,ch_out=512, drop_block=True, block_size = 5, drop_prob = drop_prob)\n","        self.Conv5 = conv_block(ch_in=512,ch_out=1024, drop_block=True, block_size = 5, drop_prob = drop_prob)\n","\n","        self.Up5 = up_conv(ch_in=1024,ch_out=512)\n","        self.Att5 = Attention_block(F_g=512,F_l=512,F_int=256)\n","        self.Up_conv5 = conv_block(ch_in=1024, ch_out=512)\n","\n","        self.Up4 = up_conv(ch_in=512,ch_out=256)\n","        self.Att4 = Attention_block(F_g=256,F_l=256,F_int=128)\n","        self.Up_conv4 = conv_block(ch_in=512, ch_out=256)\n","        \n","        self.Up3 = up_conv(ch_in=256,ch_out=128)\n","        self.Att3 = Attention_block(F_g=128,F_l=128,F_int=64)\n","        self.Up_conv3 = conv_block(ch_in=256, ch_out=128)\n","        \n","        self.Up2 = up_conv(ch_in=128,ch_out=64)\n","        self.Att2 = Attention_block(F_g=64,F_l=64,F_int=32)\n","        self.Up_conv2 = conv_block(ch_in=128, ch_out=64)\n","\n","        self.Conv_1x1 = nn.Sequential(\n","            nn.Conv2d(64, output_ch, kernel_size=1,stride=1,padding=0), \n","            nn.Softmax(dim=1)\n","            )\n","\n","    def forward(self,x):\n","        # encoding path\n","        x1 = self.Conv1(x)\n","\n","        x2 = self.Maxpool(x1)\n","        x2 = self.Conv2(x2)\n","        \n","        x3 = self.Maxpool(x2)\n","        x3 = self.Conv3(x3)\n","\n","        x4 = self.Maxpool(x3)\n","        x4 = self.Conv4(x4)\n","\n","        x5 = self.Maxpool(x4)\n","        x5 = self.Conv5(x5)\n","\n","        # decoding + concat path\n","        d5 = self.Up5(x5)\n","        x4 = self.Att5(d5,x4)\n","        d5 = torch.cat((x4,d5),dim=1)        \n","        d5 = self.Up_conv5(d5)\n","        \n","        d4 = self.Up4(d5)\n","        x3 = self.Att4(d4,x3)\n","        d4 = torch.cat((x3,d4),dim=1)\n","        d4 = self.Up_conv4(d4)\n","\n","        d3 = self.Up3(d4)\n","        x2 = self.Att3(d3,x2)\n","        d3 = torch.cat((x2,d3),dim=1)\n","        d3 = self.Up_conv3(d3)\n","\n","        d2 = self.Up2(d3)\n","        x1 = self.Att2(d2,x1)\n","        d2 = torch.cat((x1,d2),dim=1)\n","        d2 = self.Up_conv2(d2)\n","\n","        d1 = self.Conv_1x1(d2)\n","\n","        return d1\n"],"metadata":{"id":"n87qlWPVHzfU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["summary(U_Net(), (3,128,128), device=\"cpu\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sevcfVTiJNSs","executionInfo":{"status":"ok","timestamp":1647195178583,"user_tz":-420,"elapsed":795,"user":{"displayName":"Minh Nhat Trinh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUlruUlJibAIqBqbqLK2Tos6lKVv00A2KZfuwF=s64","userId":"12425805762404293245"}},"outputId":"40e36944-94e5-4305-a733-2585a784c1bc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:443: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  ../aten/src/ATen/native/Convolution.cpp:647.)\n","  self.padding, self.dilation, self.groups)\n"]},{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 32, 128, 128]             864\n","       BatchNorm2d-2         [-1, 32, 128, 128]              64\n","              ReLU-3         [-1, 32, 128, 128]               0\n","            Conv2d-4         [-1, 32, 128, 128]           9,216\n","       BatchNorm2d-5         [-1, 32, 128, 128]              64\n","              ReLU-6         [-1, 32, 128, 128]               0\n","         MaxPool2d-7           [-1, 32, 64, 64]               0\n","            Conv2d-8           [-1, 64, 64, 64]          18,432\n","       BatchNorm2d-9           [-1, 64, 64, 64]             128\n","             ReLU-10           [-1, 64, 64, 64]               0\n","           Conv2d-11           [-1, 64, 64, 64]          36,864\n","      BatchNorm2d-12           [-1, 64, 64, 64]             128\n","             ReLU-13           [-1, 64, 64, 64]               0\n","        MaxPool2d-14           [-1, 64, 32, 32]               0\n","           Conv2d-15          [-1, 128, 32, 32]          73,728\n","      BatchNorm2d-16          [-1, 128, 32, 32]             256\n","             ReLU-17          [-1, 128, 32, 32]               0\n","           Conv2d-18          [-1, 128, 32, 32]         147,456\n","      BatchNorm2d-19          [-1, 128, 32, 32]             256\n","             ReLU-20          [-1, 128, 32, 32]               0\n","        MaxPool2d-21          [-1, 128, 16, 16]               0\n","           Conv2d-22          [-1, 256, 16, 16]         294,912\n","      BatchNorm2d-23          [-1, 256, 16, 16]             512\n","             ReLU-24          [-1, 256, 16, 16]               0\n","           Conv2d-25          [-1, 256, 16, 16]         589,824\n","      DropBlock2D-26          [-1, 256, 16, 16]               0\n","      BatchNorm2d-27          [-1, 256, 16, 16]             512\n","             ReLU-28          [-1, 256, 16, 16]               0\n","        MaxPool2d-29            [-1, 256, 8, 8]               0\n","           Conv2d-30            [-1, 512, 8, 8]       1,179,648\n","      BatchNorm2d-31            [-1, 512, 8, 8]           1,024\n","             ReLU-32            [-1, 512, 8, 8]               0\n","           Conv2d-33            [-1, 512, 8, 8]       2,359,296\n","      DropBlock2D-34            [-1, 512, 8, 8]               0\n","      BatchNorm2d-35            [-1, 512, 8, 8]           1,024\n","             ReLU-36            [-1, 512, 8, 8]               0\n","         Upsample-37          [-1, 512, 16, 16]               0\n","           Conv2d-38          [-1, 256, 16, 16]         524,288\n","      BatchNorm2d-39          [-1, 256, 16, 16]             512\n","             ReLU-40          [-1, 256, 16, 16]               0\n","          up_conv-41          [-1, 256, 16, 16]               0\n","           Conv2d-42          [-1, 256, 16, 16]       1,179,648\n","      BatchNorm2d-43          [-1, 256, 16, 16]             512\n","             ReLU-44          [-1, 256, 16, 16]               0\n","           Conv2d-45          [-1, 256, 16, 16]         589,824\n","      BatchNorm2d-46          [-1, 256, 16, 16]             512\n","             ReLU-47          [-1, 256, 16, 16]               0\n","         Upsample-48          [-1, 256, 32, 32]               0\n","           Conv2d-49          [-1, 128, 32, 32]         131,072\n","      BatchNorm2d-50          [-1, 128, 32, 32]             256\n","             ReLU-51          [-1, 128, 32, 32]               0\n","          up_conv-52          [-1, 128, 32, 32]               0\n","           Conv2d-53          [-1, 128, 32, 32]         294,912\n","      BatchNorm2d-54          [-1, 128, 32, 32]             256\n","             ReLU-55          [-1, 128, 32, 32]               0\n","           Conv2d-56          [-1, 128, 32, 32]         147,456\n","      BatchNorm2d-57          [-1, 128, 32, 32]             256\n","             ReLU-58          [-1, 128, 32, 32]               0\n","         Upsample-59          [-1, 128, 64, 64]               0\n","           Conv2d-60           [-1, 64, 64, 64]          32,768\n","      BatchNorm2d-61           [-1, 64, 64, 64]             128\n","             ReLU-62           [-1, 64, 64, 64]               0\n","          up_conv-63           [-1, 64, 64, 64]               0\n","           Conv2d-64           [-1, 64, 64, 64]          73,728\n","      BatchNorm2d-65           [-1, 64, 64, 64]             128\n","             ReLU-66           [-1, 64, 64, 64]               0\n","           Conv2d-67           [-1, 64, 64, 64]          36,864\n","      BatchNorm2d-68           [-1, 64, 64, 64]             128\n","             ReLU-69           [-1, 64, 64, 64]               0\n","         Upsample-70         [-1, 64, 128, 128]               0\n","           Conv2d-71         [-1, 32, 128, 128]           8,192\n","      BatchNorm2d-72         [-1, 32, 128, 128]              64\n","             ReLU-73         [-1, 32, 128, 128]               0\n","          up_conv-74         [-1, 32, 128, 128]               0\n","           Conv2d-75         [-1, 32, 128, 128]          18,432\n","      BatchNorm2d-76         [-1, 32, 128, 128]              64\n","             ReLU-77         [-1, 32, 128, 128]               0\n","           Conv2d-78         [-1, 32, 128, 128]           9,216\n","      BatchNorm2d-79         [-1, 32, 128, 128]              64\n","             ReLU-80         [-1, 32, 128, 128]               0\n","           Conv2d-81          [-1, 2, 128, 128]              66\n","          Softmax-82          [-1, 2, 128, 128]               0\n","================================================================\n","Total params: 7,763,554\n","Trainable params: 7,763,554\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.19\n","Forward/backward pass size (MB): 139.62\n","Params size (MB): 29.62\n","Estimated Total Size (MB): 169.43\n","----------------------------------------------------------------\n"]}]},{"cell_type":"markdown","source":["##preprocessing"],"metadata":{"id":"4q2RmzNLJxKu"}},{"cell_type":"code","source":["all_train_files = glob.glob(\"/content/drive/MyDrive/deepfish/Dataset/LargeFish/Fish_Dataset/*/*/*.png\")\n","train_gt_files = glob.glob(\"/content/drive/MyDrive/deepfish/Dataset/LargeFish/Fish_Dataset/*/* GT/*.png\")\n","train_image_files = list(set(all_train_files) - set(train_gt_files))\n","\n","train_image_files = np.array(sorted(train_image_files))\n","train_gt_files = np.array(sorted(train_gt_files))\n","\n","len(train_image_files), len(train_gt_files)\n","x_train, x_val, y_train, y_val = train_test_split(train_image_files, train_gt_files, test_size = 0.2, random_state=42)"],"metadata":{"id":"z9uGbcnIJ2eD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# data = np.load(\"./dataISIC2018/ISIC2018_192_256.npz\")\n","# x,y = data[\"image\"], data[\"mask\"]\n","# test_size = int((10/100)*x.shape[0])\t\n","# x_train, x_val, y_train, y_val = train_test_split(x, y, test_size = test_size, random_state=42)"],"metadata":{"id":"Nbq4cTe0YjWY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["BATCH_SIZE = 16\n","train_dataset = DataLoader(FishLoader(x_train, y_train, transform=False), batch_size=BATCH_SIZE, pin_memory=True,\n","                        shuffle=True, num_workers=2, \n","                        drop_last=True, prefetch_factor = BATCH_SIZE)\n","val_dataset = DataLoader(FishLoader(x_val, y_val, typeData=\"test\"), batch_size=BATCH_SIZE * 2,\n","                          num_workers=2, prefetch_factor=BATCH_SIZE * 2)"],"metadata":{"id":"KZ-HSskYTjZ9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Segmentor(pl.LightningModule):\n","    def __init__(self, model = U_Net(drop_prob=0)):\n","        super().__init__()\n","        self.model = model\n","    def forward(self, x):\n","        return self.model(x)\n","    def get_metrics(self):\n","        # don't show the version number\n","        items = super().get_metrics()\n","        items.pop(\"v_num\", None)\n","        return items\n","\n","    # def _step(self, batch):\n","    #     image, y_true = batch\n","    #     y_pred = self.model(image)\n","    #     loss = SemiActiveLoss(device=self.device)(image, y_true, y_pred)\n","    #     dice_score, jaccard_score = dice(y_true, y_pred), jaccard(y_true, y_pred)\n","    #     return loss, dice_score, jaccard_score\n","    def _step(self, batch):\n","        image, y_true = batch\n","        y_val = y_true[:,0]\n","        y_pred = self.model(image)\n","        loss = DiceLoss(device=self.device)(y_true, y_pred)\n","        dice_score, jaccard_score = dice(y_true, y_pred), jaccard(y_true, y_pred)\n","        return loss, dice_score, jaccard_score\n","\n","    def training_step(self, batch, batch_idx):\n","        loss, dice_score, jaccard_score = self._step(batch)\n","        metrics = {\"loss\": loss, \"train_dice\": dice_score, \"train_jac\": jaccard_score}\n","        self.log_dict(metrics, on_step=True, on_epoch=True, prog_bar = True)\n","        return loss\n","\n","    def validation_step(self, batch, batch_idx):\n","        loss, dice_score, jaccard_score = self._step(batch)\n","        metrics = {\"val_loss\": loss, \"val_dice\": dice_score, \"val_jac\":jaccard_score}\n","        self.log_dict(metrics, prog_bar = True)\n","        return metrics\n","\n","    def test_step(self, batch, batch_idx):\n","        loss, dice_score, jaccard_score = self._step(batch)\n","        metrics = {\"test_loss\": loss, \"test_dice\": dice_score, \"test_jac\":jaccard_score}\n","        self.log_dict(metrics, prog_bar = True)\n","        return metrics\n","        \n","\n","    def configure_optimizers(self):\n","        optimizer = Nadam(self.parameters(), lr=1e-3)\n","        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\",\n","                                                         factor = 0.5, patience=15, verbose =True)\n","        lr_schedulers = {\"scheduler\": scheduler, \"monitor\": \"val_dice\"}\n","        return [optimizer], lr_schedulers\n","    "],"metadata":{"id":"BrmkdA2EUQzb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["segmentor = Segmentor(U_Net(drop_prob=0))\n","check_point = pl.callbacks.model_checkpoint.ModelCheckpoint(\"./sample_data/\", filename=\"ckpt{val_dice:0.4f}\",\n","                                                            monitor=\"val_dice\", mode = \"max\", save_top_k =1,\n","                                                            verbose=True, save_weights_only=True,\n","                                                            auto_insert_metric_name=False,)\n","progress_bar = pl.callbacks.TQDMProgressBar()\n","logger = HistoryLogger()\n","swa = pl.callbacks.StochasticWeightAveraging(swa_epoch_start=25)\n","PARAMS = {\"gpus\":1, \"benchmark\": True, \"enable_progress_bar\" : False, \"logger\":False,\n","        #   \"callbacks\" : [progress_bar], \n","        #    \"overfit_batches\" :1, \n","          \"callbacks\" : [check_point, progress_bar, logger], \n","          \"log_every_n_steps\" :1, \"num_sanity_val_steps\":1, \"max_epochs\":10,\n","          \"precision\":16,\n","          }\n","\n","trainer = pl.Trainer(**PARAMS)\n","# segmentor = Segmentor.load_from_checkpoint(checkpoint_path=\"./weightUnet/current.ckpt\") \n","# segmentor = Segmentor.load_from_checkpoint(checkpoint_path=\"./sample_data/ckpt0.7812.ckpt\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uxFjeAzSUiB6","executionInfo":{"status":"ok","timestamp":1647195769897,"user_tz":-420,"elapsed":439,"user":{"displayName":"Minh Nhat Trinh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUlruUlJibAIqBqbqLK2Tos6lKVv00A2KZfuwF=s64","userId":"12425805762404293245"}},"outputId":"b53b72a9-63c5-4e78-874a-05ff378458f9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Using 16bit native Automatic Mixed Precision (AMP)\n","GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n"]}]},{"cell_type":"code","source":["trainer.fit(segmentor, train_dataset, val_dataset)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":268,"referenced_widgets":["b657d460a5e846e4aad85859a4c3a890","c11da44e282f4a8b96dd6a0f738bd2f9","7b118c232b8e406b9373fd5624192fda","b48e0b305c4440508d9617172c57b51b","071ae621e7db450c98e70e2284b3263b","e6840c3c96dd4b619c7228c4bd4147ff","e46b6f04642d49ca99cc0a604d84f2e4","9cec10754c9444b28d20fa40a994024f","c2b1a39b3a28419bba2d58f8186d3ad8","9c3eb955b5a340c0a0eeb79b2f9d3827","9bcd99a4a54f491eb51ec3c8f26fd8c7","9f14eb3fbb4f4d608a5c7b96338ac07c","194d1528c926410f8e34a593b89f8fcc","c7d1c23f0fe74ce596b4970f56810042","f81ef4896e6848509adaf8083df733f8","39f34bb33f2144ab85701c8f75bf7052","24aff7b4028c4f7b8979c0d44040518d","062800414ebc46c6a1f36c751aa43f13","dc6aea14ddbf4c078897648680a60437","bc7277b01c554125910402e524cef66b","0c26d4b51bb54b9387a0b0c3e42de17d","b2e2f243ed7a4cc1a06a5f0e365464ff"]},"id":"1S0NM3y3UwjE","outputId":"25ad2995-bd91-4651-b85b-a2c705f6784e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","  | Name  | Type  | Params\n","--------------------------------\n","0 | model | U_Net | 7.8 M \n","--------------------------------\n","7.8 M     Trainable params\n","0         Non-trainable params\n","7.8 M     Total params\n","15.527    Total estimated model params size (MB)\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /content/sample_data exists and is not empty.\n","  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"]},{"output_type":"display_data","data":{"text/plain":["Validation sanity check: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b657d460a5e846e4aad85859a4c3a890"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Training: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f14eb3fbb4f4d608a5c7b96338ac07c"}},"metadata":{}}]},{"cell_type":"code","source":[""],"metadata":{"id":"r46gNEiEU1A8"},"execution_count":null,"outputs":[]}]}