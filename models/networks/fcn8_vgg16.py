import torch.nn as nn
import torchvision
import torch, os
from skimage import morphology as morph
import numpy as np
from src.modules.eprop import eprop
import torch.utils.model_zoo as model_zoo
from scripts.SEAM.network import resnet38_SEAM, resnet38_aff


#----------- LC-FCN8
class FCN8VGG16(nn.Module):
    def __init__(self, n_classes, with_attention=False, with_affinity=False,
                with_affinity_average=False, shared=False, exp_dict=None):
        super().__init__()
        self.n_classes = n_classes
        self.shared = shared
        # PREDEFINE LAYERS
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True)
        self.relu = nn.ReLU(inplace=True)
      
        # VGG16 PART
        self.conv1_1 = conv3x3(3, 64, stride=1, padding=100)
        self.conv1_2 = conv3x3(64, 64)
        
        self.conv2_1 = conv3x3(64, 128)
        self.conv2_2 = conv3x3(128, 128)
        
        self.conv3_1 = conv3x3(128, 256)
        self.conv3_2 = conv3x3(256, 256)
        self.conv3_3 = conv3x3(256, 256)

        self.conv4_1 = conv3x3(256, 512)
        self.conv4_2 = conv3x3(512, 512)
        self.conv4_3 = conv3x3(512, 512)

        self.conv5_1 = conv3x3(512, 512)
        self.conv5_2 = conv3x3(512, 512)
        self.conv5_3 = conv3x3(512, 512)
        
        self.fc6 = nn.Conv2d(512, 4096, kernel_size=7, stride=1, padding=0)
        self.dropout_f6 = nn.Dropout()
        self.fc7 = nn.Conv2d(4096, 4096, kernel_size=1, stride=1, padding=0)
        self.dropout_f7 = nn.Dropout()
        # SEMANTIC SEGMENTAION PART
        self.scoring_layer = nn.Conv2d(4096, self.n_classes, kernel_size=1, 
                                      stride=1, padding=0)

        self.upscore2 = nn.ConvTranspose2d(self.n_classes, self.n_classes, 
                                          kernel_size=4, stride=2, bias=False)
        self.upscore_pool4 = nn.ConvTranspose2d(self.n_classes, self.n_classes,
                                         kernel_size=4, stride=2, bias=False)
        self.upscore8 = nn.ConvTranspose2d(self.n_classes, self.n_classes, 
                                    kernel_size=16, stride=8, bias=False)
        
        # Initilize Weights
        self.scoring_layer.weight.data.zero_()
        self.scoring_layer.bias.data.zero_()
        
        self.score_pool3 = nn.Conv2d(256, self.n_classes, kernel_size=1)
        self.score_pool4 = nn.Conv2d(512, self.n_classes, kernel_size=1)
        self.score_pool3.weight.data.zero_()
        self.score_pool3.bias.data.zero_()
        self.score_pool4.weight.data.zero_()
        self.score_pool4.bias.data.zero_()

        self.upscore2.weight.data.copy_(get_upsampling_weight(self.n_classes, self.n_classes, 4))
        self.upscore_pool4.weight.data.copy_(get_upsampling_weight(self.n_classes, self.n_classes, 4))
        self.upscore8.weight.data.copy_(get_upsampling_weight(self.n_classes, self.n_classes, 16))
        self.eprop = eprop.EmbeddingPropagation()
        # Pretrained layers
        pth_url = 'https://download.pytorch.org/models/vgg16-397923af.pth' # download from model zoo
        state_dict = model_zoo.load_url(pth_url)

        layer_names = [layer_name for layer_name in state_dict]

        
        counter = 0
        for p in self.parameters():
            if counter < 26:  # conv1_1 to pool5
                p.data = state_dict[ layer_names[counter] ]
            elif counter == 26:  # fc6 weight
                p.data = state_dict[ layer_names[counter] ].view(4096, 512, 7, 7)
            elif counter == 27:  # fc6 bias
                p.data = state_dict[ layer_names[counter] ]
            elif counter == 28:  # fc7 weight
                p.data = state_dict[ layer_names[counter] ].view(4096, 4096, 1, 1)
            elif counter == 29:  # fc7 bias
                p.data = state_dict[ layer_names[counter] ]


            counter += 1
        self.with_attention = with_attention
        if with_attention:
            
            self.att1 = Attention_block(self.n_classes, 
                                        self.n_classes,
                                        self.n_classes).cuda()
            self.att2 = Attention_block(self.n_classes, 
                                        self.n_classes,
                                        self.n_classes).cuda()
        self.with_affinity = with_affinity
        if with_affinity or self.shared:
            self.model_aff = resnet38_aff.Net(self.n_classes, exp_dict).cuda()
            self.model_aff.load_state_dict(torch.load('/content/drive/MyDrive/deepfish/weight/resnet38_aff_SEAM.pth'), strict=False)

        self.with_affinity_average = with_affinity_average
        # siamese 
        # self.siamese_network = Siamese()

        

    def forward(self, x, return_features=False, return_cam=False, crf=False):
        n,c,h,w = x.size()
        #print('x: ', x.shape)
        # VGG16 PART
        conv1_1 =  self.relu(  self.conv1_1(x) )
        conv1_2 =  self.relu(  self.conv1_2(conv1_1) )
        pool1 = self.pool(conv1_2)
        #print('pool1: ', pool1.shape) #[1, 64, 355, 355]
        
        conv2_1 =  self.relu(   self.conv2_1(pool1) )
        conv2_2 =  self.relu(   self.conv2_2(conv2_1) )
        pool2 = self.pool(conv2_2)
        # pool2 = self.eprop(pool2)
        #print('pool2: ', pool2.shape) #[1, 128, 178, 178]

        conv3_1 =  self.relu(   self.conv3_1(pool2) )
        conv3_2 =  self.relu(   self.conv3_2(conv3_1) )
        conv3_3 =  self.relu(   self.conv3_3(conv3_2) )
        pool3 = self.pool(conv3_3)
        #print('pool3: ', pool3.shape) #[1, 256, 89, 89]
        
        conv4_1 =  self.relu(   self.conv4_1(pool3) )
        conv4_2 =  self.relu(   self.conv4_2(conv4_1) )
        conv4_3 =  self.relu(   self.conv4_3(conv4_2) )
        pool4 = self.pool(conv4_3)
        #print('pool4: ', pool4.shape) #[1, 512, 45, 45]
        
        conv5_1 =  self.relu(   self.conv5_1(pool4) )
        conv5_2 =  self.relu(   self.conv5_2(conv5_1) )
        conv5_3 =  self.relu(   self.conv5_3(conv5_2) )
        pool5 = self.pool(conv5_3)
        #print('pool5: ', pool5.shape) #[1, 512, 23, 23]
        
        fc6 = self.dropout_f6( self.relu(   self.fc6(pool5) ) )
        #print('fc6: ', fc6.shape) #[1, 4096, 17, 17]
        fc7 = self.dropout_f7( self.relu(   self.fc7(fc6) ) )
        #print('fc7: ', fc7.shape) #[1, 4096, 17, 17]
         
        # SEMANTIC SEGMENTATION PART
        # first
        scores = self.scoring_layer( fc7 )
        #print('scores: ', scores.shape) #[1, 2, 17, 17]
        upscore2 = self.upscore2(scores)
        #print('upscore2: ', upscore2.shape) #[1, 2, 36, 36]

        # second
        score_pool4 = self.score_pool4(pool4)
        #print('score_pool4: ', score_pool4.shape) #[1, 2, 45, 45]
        score_pool4c = score_pool4[:, :, 5:5+upscore2.size(2), 5:5+upscore2.size(3)]
        #print('score_pool4c: ', score_pool4c.shape) #[1, 2, 36, 36]
        if self.with_attention:
            score_pool4c = self.att1(g=upscore2, x=score_pool4c)
        upscore_pool4 = self.upscore_pool4(score_pool4c + upscore2)
        #print('upscore_pool4: ', upscore_pool4.shape) #[1, 2, 74, 74]
        
        # third
        score_pool3 = self.score_pool3(pool3)
        #print('score_pool3: ', score_pool3.shape) #[1, 2, 89, 89]
        score_pool3c = score_pool3[:, :, 9:9+upscore_pool4.size(2), 9:9+upscore_pool4.size(3)]
        #print('score_pool3c: ', score_pool3c.shape) #[1, 2, 74, 74]
        if self.with_attention:
            score_pool3c = self.att2(g=upscore_pool4, x=score_pool3c)

        output = self.upscore8(score_pool3c + upscore_pool4) 
        #print('output: ', output.shape) #[1, 2, 600, 600]
        logits = output[:, :, 31: (31 + h), 31: (31 + w)].contiguous()
        #print(logits.shape) #[1,2,512,512]

        if self.shared:
            logits = cam = self.model_aff.output_logits(x)
        if self.with_affinity:
            logits_aff = self.model_aff.apply_affinity(x, logits, crf=crf)

            if self.with_affinity_average:
                logits = (logits_aff + logits) / 2.
            else:
                logits = logits_aff

        if return_features:
            return logits, upscore_pool4, fc7

        if return_cam:
            return cam, logits_aff
        return logits

# ===========================================================
# helpers
def get_upsampling_weight(in_channels, out_channels, kernel_size):
    """Make a 2D bilinear kernel suitable for upsampling"""
    factor = (kernel_size + 1) // 2
    if kernel_size % 2 == 1:
        center = factor - 1
    else:
        center = factor - 0.5
    og = np.ogrid[:kernel_size, :kernel_size]
    filt = (1 - abs(og[0] - center) / factor) * \
           (1 - abs(og[1] - center) / factor)
    weight = np.zeros((in_channels, out_channels, kernel_size, kernel_size),
                      dtype=np.float64)
    weight[range(in_channels), range(out_channels), :, :] = filt
    return torch.from_numpy(weight).float()


def conv3x3(in_planes, out_planes, stride=1, padding=1):
    "3x3 convolution with padding"
    return nn.Conv2d(in_planes, out_planes, kernel_size=(3,3), stride=(stride,stride),
                     padding=(padding,padding))

def conv1x1(in_planes, out_planes, stride=1):
    "1x1 convolution with padding"
    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,
                     padding=0)

class Attention_block(nn.Module):
    def __init__(self,F_g,F_l,F_int):
        super(Attention_block,self).__init__()
        self.W_g = nn.Sequential(
            nn.Conv2d(F_g, F_int, kernel_size=1,stride=1,padding=0,bias=True),
            # nn.BatchNorm2d(F_int)
            )
        
        self.W_x = nn.Sequential(
            nn.Conv2d(F_l, F_int, kernel_size=1,stride=1,padding=0,bias=True),
            # nn.BatchNorm2d(F_int)
        )

        self.psi = nn.Sequential(
            nn.Conv2d(F_int, 1, kernel_size=1,stride=1,padding=0,bias=True),
            # nn.BatchNorm2d(1),
            nn.Sigmoid()
        )
        
        self.relu = nn.ReLU(inplace=True)
        
    def forward(self,g,x):
        g1 = self.W_g(g)
        x1 = self.W_x(x)
        psi = self.relu(g1+x1)
        psi = self.psi(psi)

        return x*psi


import torch
import torch.nn as nn
import torch.nn.functional as F




class Siamese(nn.Module):

    def __init__(self):
        super(Siamese, self).__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(2, 64, 10),  # 64@96*96
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2),  # 64@48*48
            nn.Conv2d(64, 128, 7),
            nn.ReLU(),    # 128@42*42
            nn.MaxPool2d(2),   # 128@21*21
            nn.Conv2d(128, 128, 4),
            nn.ReLU(), # 128@18*18
            nn.MaxPool2d(2), # 128@9*9
            nn.Conv2d(128, 256, 4),
            nn.ReLU(),   # 256@6*6
        )
        self.liner = nn.Sequential(nn.Linear(4096, 4096), nn.Sigmoid())
        self.out = nn.Linear(4096, 1)

    def forward_one(self, x):
        x = self.conv(x)
        x = x.view(x.size()[0], -1)
        x = self.liner(x)
        return x

    def forward(self, x1, x2):
        out1 = self.forward_one(x1)
        out2 = self.forward_one(x2)
        dis = torch.abs(out1 - out2)
        out = self.out(dis)
        #  return self.sigmoid(out)
        return out